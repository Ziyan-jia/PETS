{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pybullet as p\n",
    "import pybullet_data \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physicsClient = p.connect(p.GUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.setGravity(0,0,-10) \n",
    "p.resetSimulation() \n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath()) \n",
    "planeId = p.loadURDF(\"plane.urdf\") \n",
    "robotId = p.loadURDF(\"iiwa7.urdf\",flags=9, useFixedBase=1)\n",
    "\n",
    "robotStartPos = [0,0,0]\n",
    "robotStartOrientation = p.getQuaternionFromEuler([0,0,0])\n",
    "\n",
    "p.resetBasePositionAndOrientation(robotId,robotStartPos,robotStartOrientation)\n",
    "\n",
    "p.setJointMotorControlArray(robotId,range(7),p.VELOCITY_CONTROL,forces=np.zeros(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_system(x, u):\n",
    "    x_next=[]\n",
    "    for i in range(7):\n",
    "        p.resetJointState(robotId,i,x[i],targetVelocity = x[i+7])\n",
    "    \n",
    "    p.setJointMotorControlArray(robotId,range(7), controlMode=p.TORQUE_CONTROL,forces=u)\n",
    "    p.stepSimulation()\n",
    "    for i in range(7):\n",
    "        x_next.append(p.getJointStates(robotId,range(7))[i][0])\n",
    "    for i in range(7):\n",
    "        x_next.append(p.getJointStates(robotId,range(7))[i][1])\n",
    "    x_next = np.array(x_next)\n",
    "    return x_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=2000\n",
    "x = np.zeros([14,N])\n",
    "u= np.zeros([7, N])\n",
    "x_new=np.zeros([14,N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    for j in range(7):\n",
    "        a=random.randint(-180,180)#angule range(-pi,pi)\n",
    "        b=random.uniform(-10, 10)#velocity range\n",
    "        c=random.randint(-30,30)#torque range (-200,200)\n",
    "        x[j,i]=math.radians(a/math.pi)\n",
    "        x[j+7,i]=b\n",
    "        u[j,i]=c\n",
    "            \n",
    "for i in range(N):\n",
    "    x_new[:,i]=simulate_system(x[:,i], u[:,i])\n",
    "        \n",
    "x=x.T\n",
    "u = u.T\n",
    "x_train = np.append(x,u,axis=1)\n",
    "y_train = x_new.T\n",
    "x_train = x_train.astype(np.float32)\n",
    "y_train=y_train.astype(np.float32)\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, loss:7.368406\n",
      "Epoch:200, loss:3.390052\n",
      "Epoch:300, loss:1.869053\n",
      "Epoch:400, loss:1.284193\n",
      "Epoch:500, loss:1.057715\n",
      "Epoch:600, loss:0.968725\n",
      "Epoch:700, loss:0.932599\n",
      "Epoch:800, loss:0.916856\n",
      "Epoch:900, loss:0.909001\n",
      "Epoch:1000, loss:0.904218\n",
      "Epoch:1100, loss:0.900645\n",
      "Epoch:1200, loss:0.897563\n",
      "Epoch:1300, loss:0.894691\n",
      "Epoch:1400, loss:0.891919\n",
      "Epoch:1500, loss:0.889206\n",
      "Epoch:1600, loss:0.886535\n",
      "Epoch:1700, loss:0.883898\n",
      "Epoch:1800, loss:0.881292\n",
      "Epoch:1900, loss:0.878716\n",
      "Epoch:2000, loss:0.876170\n",
      "Epoch:2100, loss:0.873652\n",
      "Epoch:2200, loss:0.871162\n",
      "Epoch:2300, loss:0.868700\n",
      "Epoch:2400, loss:0.866266\n",
      "Epoch:2500, loss:0.863858\n",
      "Epoch:2600, loss:0.861478\n",
      "Epoch:2700, loss:0.859123\n",
      "Epoch:2800, loss:0.856795\n",
      "Epoch:2900, loss:0.854492\n",
      "Epoch:3000, loss:0.852214\n",
      "Epoch:3100, loss:0.849962\n",
      "Epoch:3200, loss:0.847734\n",
      "Epoch:3300, loss:0.845530\n",
      "Epoch:3400, loss:0.843350\n",
      "Epoch:3500, loss:0.841194\n",
      "Epoch:3600, loss:0.839061\n",
      "Epoch:3700, loss:0.836951\n",
      "Epoch:3800, loss:0.834864\n",
      "Epoch:3900, loss:0.832800\n",
      "Epoch:4000, loss:0.830757\n",
      "Epoch:4100, loss:0.828737\n",
      "Epoch:4200, loss:0.826738\n",
      "Epoch:4300, loss:0.824760\n",
      "Epoch:4400, loss:0.822804\n",
      "Epoch:4500, loss:0.820868\n",
      "Epoch:4600, loss:0.818953\n",
      "Epoch:4700, loss:0.817058\n",
      "Epoch:4800, loss:0.815183\n",
      "Epoch:4900, loss:0.813329\n",
      "Epoch:5000, loss:0.811493\n",
      "Epoch:5100, loss:0.809677\n",
      "Epoch:5200, loss:0.807880\n",
      "Epoch:5300, loss:0.806102\n",
      "Epoch:5400, loss:0.804342\n",
      "Epoch:5500, loss:0.802601\n",
      "Epoch:5600, loss:0.800878\n",
      "Epoch:5700, loss:0.799173\n",
      "Epoch:5800, loss:0.797485\n",
      "Epoch:5900, loss:0.795815\n",
      "Epoch:6000, loss:0.794163\n",
      "Epoch:6100, loss:0.792527\n",
      "Epoch:6200, loss:0.790909\n",
      "Epoch:6300, loss:0.789307\n",
      "Epoch:6400, loss:0.787722\n",
      "Epoch:6500, loss:0.786153\n",
      "Epoch:6600, loss:0.784600\n",
      "Epoch:6700, loss:0.783063\n",
      "Epoch:6800, loss:0.781542\n",
      "Epoch:6900, loss:0.780036\n",
      "Epoch:7000, loss:0.778546\n",
      "Epoch:7100, loss:0.777071\n",
      "Epoch:7200, loss:0.775611\n",
      "Epoch:7300, loss:0.774166\n",
      "Epoch:7400, loss:0.772736\n",
      "Epoch:7500, loss:0.771320\n",
      "Epoch:7600, loss:0.769919\n",
      "Epoch:7700, loss:0.768532\n",
      "Epoch:7800, loss:0.767158\n",
      "Epoch:7900, loss:0.765799\n",
      "Epoch:8000, loss:0.764454\n",
      "Epoch:8100, loss:0.763122\n",
      "Epoch:8200, loss:0.761803\n",
      "Epoch:8300, loss:0.760498\n",
      "Epoch:8400, loss:0.759206\n",
      "Epoch:8500, loss:0.757926\n",
      "Epoch:8600, loss:0.756660\n",
      "Epoch:8700, loss:0.755407\n",
      "Epoch:8800, loss:0.754166\n",
      "Epoch:8900, loss:0.752937\n",
      "Epoch:9000, loss:0.751721\n",
      "Epoch:9100, loss:0.750517\n",
      "Epoch:9200, loss:0.749324\n",
      "Epoch:9300, loss:0.748144\n",
      "Epoch:9400, loss:0.746976\n",
      "Epoch:9500, loss:0.745819\n",
      "Epoch:9600, loss:0.744673\n",
      "Epoch:9700, loss:0.743540\n",
      "Epoch:9800, loss:0.742417\n",
      "Epoch:9900, loss:0.741305\n",
      "Epoch:10000, loss:0.740205\n",
      "Epoch:10100, loss:0.739115\n",
      "Epoch:10200, loss:0.738036\n",
      "Epoch:10300, loss:0.736968\n",
      "Epoch:10400, loss:0.735910\n",
      "Epoch:10500, loss:0.734863\n",
      "Epoch:10600, loss:0.733826\n",
      "Epoch:10700, loss:0.732800\n",
      "Epoch:10800, loss:0.731783\n",
      "Epoch:10900, loss:0.730777\n",
      "Epoch:11000, loss:0.729780\n",
      "Epoch:11100, loss:0.728794\n",
      "Epoch:11200, loss:0.727817\n",
      "Epoch:11300, loss:0.726849\n",
      "Epoch:11400, loss:0.725891\n",
      "Epoch:11500, loss:0.724943\n",
      "Epoch:11600, loss:0.724003\n",
      "Epoch:11700, loss:0.723073\n",
      "Epoch:11800, loss:0.722152\n",
      "Epoch:11900, loss:0.721241\n",
      "Epoch:12000, loss:0.720338\n",
      "Epoch:12100, loss:0.719443\n",
      "Epoch:12200, loss:0.718558\n",
      "Epoch:12300, loss:0.717681\n",
      "Epoch:12400, loss:0.716813\n",
      "Epoch:12500, loss:0.715953\n",
      "Epoch:12600, loss:0.715102\n",
      "Epoch:12700, loss:0.714259\n",
      "Epoch:12800, loss:0.713424\n",
      "Epoch:12900, loss:0.712597\n",
      "Epoch:13000, loss:0.711779\n",
      "Epoch:13100, loss:0.710968\n",
      "Epoch:13200, loss:0.710165\n",
      "Epoch:13300, loss:0.709370\n",
      "Epoch:13400, loss:0.708583\n",
      "Epoch:13500, loss:0.707803\n",
      "Epoch:13600, loss:0.707031\n",
      "Epoch:13700, loss:0.706266\n",
      "Epoch:13800, loss:0.705509\n",
      "Epoch:13900, loss:0.704759\n",
      "Epoch:14000, loss:0.704017\n",
      "Epoch:14100, loss:0.703281\n",
      "Epoch:14200, loss:0.702553\n",
      "Epoch:14300, loss:0.701832\n",
      "Epoch:14400, loss:0.701117\n",
      "Epoch:14500, loss:0.700410\n",
      "Epoch:14600, loss:0.699710\n",
      "Epoch:14700, loss:0.699016\n",
      "Epoch:14800, loss:0.698329\n",
      "Epoch:14900, loss:0.697649\n",
      "Epoch:15000, loss:0.696975\n",
      "Epoch:15100, loss:0.696307\n",
      "Epoch:15200, loss:0.695646\n",
      "Epoch:15300, loss:0.694992\n",
      "Epoch:15400, loss:0.694344\n",
      "Epoch:15500, loss:0.693702\n",
      "Epoch:15600, loss:0.693066\n",
      "Epoch:15700, loss:0.692436\n",
      "Epoch:15800, loss:0.691813\n",
      "Epoch:15900, loss:0.691195\n",
      "Epoch:16000, loss:0.690583\n",
      "Epoch:16100, loss:0.689978\n",
      "Epoch:16200, loss:0.689378\n",
      "Epoch:16300, loss:0.688783\n",
      "Epoch:16400, loss:0.688195\n",
      "Epoch:16500, loss:0.687612\n",
      "Epoch:16600, loss:0.687035\n",
      "Epoch:16700, loss:0.686463\n",
      "Epoch:16800, loss:0.685897\n",
      "Epoch:16900, loss:0.685336\n",
      "Epoch:17000, loss:0.684781\n",
      "Epoch:17100, loss:0.684231\n",
      "Epoch:17200, loss:0.683686\n",
      "Epoch:17300, loss:0.683147\n",
      "Epoch:17400, loss:0.682612\n",
      "Epoch:17500, loss:0.682083\n",
      "Epoch:17600, loss:0.681559\n",
      "Epoch:17700, loss:0.681040\n",
      "Epoch:17800, loss:0.680526\n",
      "Epoch:17900, loss:0.680016\n",
      "Epoch:18000, loss:0.679512\n",
      "Epoch:18100, loss:0.679012\n",
      "Epoch:18200, loss:0.678518\n",
      "Epoch:18300, loss:0.678028\n",
      "Epoch:18400, loss:0.677542\n",
      "Epoch:18500, loss:0.677061\n",
      "Epoch:18600, loss:0.676585\n",
      "Epoch:18700, loss:0.676114\n",
      "Epoch:18800, loss:0.675647\n",
      "Epoch:18900, loss:0.675184\n",
      "Epoch:19000, loss:0.674726\n",
      "Epoch:19100, loss:0.674272\n",
      "Epoch:19200, loss:0.673823\n",
      "Epoch:19300, loss:0.673378\n",
      "Epoch:19400, loss:0.672937\n",
      "Epoch:19500, loss:0.672500\n",
      "Epoch:19600, loss:0.672067\n",
      "Epoch:19700, loss:0.671639\n",
      "Epoch:19800, loss:0.671215\n",
      "Epoch:19900, loss:0.670794\n",
      "Epoch:20000, loss:0.670378\n",
      "Epoch:20100, loss:0.669966\n",
      "Epoch:20200, loss:0.669558\n",
      "Epoch:20300, loss:0.669153\n",
      "Epoch:20400, loss:0.668752\n",
      "Epoch:20500, loss:0.668356\n",
      "Epoch:20600, loss:0.667963\n",
      "Epoch:20700, loss:0.667573\n",
      "Epoch:20800, loss:0.667188\n",
      "Epoch:20900, loss:0.666806\n",
      "Epoch:21000, loss:0.666428\n",
      "Epoch:21100, loss:0.666053\n",
      "Epoch:21200, loss:0.665682\n",
      "Epoch:21300, loss:0.665314\n",
      "Epoch:21400, loss:0.664950\n",
      "Epoch:21500, loss:0.664590\n",
      "Epoch:21600, loss:0.664233\n",
      "Epoch:21700, loss:0.663879\n",
      "Epoch:21800, loss:0.663529\n",
      "Epoch:21900, loss:0.663181\n",
      "Epoch:22000, loss:0.662838\n",
      "Epoch:22100, loss:0.662497\n",
      "Epoch:22200, loss:0.662160\n",
      "Epoch:22300, loss:0.661826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d913be2fa743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2928\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2929\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MultiLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(21,14)  \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = MultiLinearRegression()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "epoch = 0\n",
    "while epoch<=100000:\n",
    "    output = model(x_train)  \n",
    "    loss = criterion(output, y_train)  \n",
    "    loss_value = loss.data.cpu().numpy() \n",
    "    optimizer.zero_grad()  \n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    \n",
    "    epoch += 1\n",
    "    if epoch % 100 == 0: \n",
    "        print('Epoch:{}, loss:{:.6f}'.format(epoch, loss_value))\n",
    "    if loss_value <= 1e-3:\n",
    "        break\n",
    "w = model.linear.weight.data.numpy()\n",
    "b = model.linear.bias.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.linear.weight.data.numpy()\n",
    "b = model.linear.bias.data.numpy()\n",
    "print('w:{},b:{}'.format(w,b))\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
